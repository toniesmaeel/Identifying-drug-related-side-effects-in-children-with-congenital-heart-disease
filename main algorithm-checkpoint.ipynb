import pandas as pd
import numpy as np
import os
import warnings
import plotly.graph_objects as go
import plotly.express as px
from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve
from sklearn.feature_selection import mutual_info_classif, RFECV
from sklearn.feature_selection import VarianceThreshold
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import plotly.figure_factory as ff
import seaborn as sns
import matplotlib.pyplot as plt
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit.DataStructs import TanimotoSimilarity
import umap
import scipy.cluster.hierarchy as sch
from scipy.spatial.distance import pdist, squareform
import shap
import json

# --- Suppress Warnings ---
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# --- Table 2: Drug Classification Across Domains ---
DRUG_CLASSIFICATION = {
    'Amiodarone': {
        'chemical_class': 'Complex',
        'chemical_class_group': 4,
        'target_class': 'Ion channel',
        'target_class_group': 3,
        'enzyme_class': 'Metabolized by CYP450',
        'enzyme_class_group': 2,
        'pathway_category': 'Cardio',
        'pathway_category_group': 1,
        'therapeutic_class': 'Antiarrhythmic',
        'therapeutic_class_group': 4,
        'phenotype_class': 'Cardio',
        'phenotype_class_group': 1
    },
    'Aspirin': {
        'chemical_class': 'Aromatic',
        'chemical_class_group': 0,
        'target_class': 'Oxidoreductase',
        'target_class_group': 0,
        'enzyme_class': 'COX',
        'enzyme_class_group': 0,
        'pathway_category': 'Immune',
        'pathway_category_group': 0,
        'therapeutic_class': 'Antiplatelet',
        'therapeutic_class_group': 0,
        'phenotype_class': 'Heme',
        'phenotype_class_group': 0
    },
    'Atenolol': {
        'chemical_class': 'Heterocyclic',
        'chemical_class_group': 2,
        'target_class': 'GPCR',
        'target_class_group': 2,
        'enzyme_class': 'Minimal hepatic metabolism',
        'enzyme_class_group': 5,
        'pathway_category': 'Cardio',
        'pathway_category_group': 1,
        'therapeutic_class': 'Antihypertensive',
        'therapeutic_class_group': 1,
        'phenotype_class': 'Cardio',
        'phenotype_class_group': 1
    },
    'Captopril': {
        'chemical_class': 'Nitrogenous',
        'chemical_class_group': 1,
        'target_class': 'Peptidase',
        'target_class_group': 1,
        'enzyme_class': 'ACE',
        'enzyme_class_group': 1,
        'pathway_category': 'Cardio',
        'pathway_category_group': 1,
        'therapeutic_class': 'Antihypertensive',
        'therapeutic_class_group': 1,
        'phenotype_class': 'Cardio',
        'phenotype_class_group': 1
    },
    'Dexmedetomidine': {
        'chemical_class': 'Nitrogenous',
        'chemical_class_group': 1,
        'target_class': 'GPCR',
        'target_class_group': 2,
        'enzyme_class': 'Metabolized by CYP450',
        'enzyme_class_group': 2,
        'pathway_category': 'Neuro',
        'pathway_category_group': 2,
        'therapeutic_class': 'Sedative',
        'therapeutic_class_group': 2,
        'phenotype_class': 'Neuro',
        'phenotype_class_group': 2
    },
    'Flecainide': {
        'chemical_class': 'Aromatic',
        'chemical_class_group': 0,
        'target_class': 'Ion channel',
        'target_class_group': 3,
        'enzyme_class': 'Metabolized by CYP450',
        'enzyme_class_group': 2,
        'pathway_category': 'Cardio',
        'pathway_category_group': 1,
        'therapeutic_class': 'Antiarrhythmic',
        'therapeutic_class_group': 4,
        'phenotype_class': 'Cardio',
        'phenotype_class_group': 1
    },
    'Furosemide': {
        'chemical_class': 'Halogenated',
        'chemical_class_group': 3,
        'target_class': 'Transporter',
        'target_class_group': 4,
        'enzyme_class': 'Minimal hepatic metabolism',
        'enzyme_class_group': 5,
        'pathway_category': 'Renal',
        'pathway_category_group': 3,
        'therapeutic_class': 'Diuretic',
        'therapeutic_class_group': 5,
        'phenotype_class': 'Renal',
        'phenotype_class_group': 4
    },
    'Heparin': {
        'chemical_class': 'Complex',
        'chemical_class_group': 4,
        'target_class': 'Protease Inhibitor',
        'target_class_group': 5,
        'enzyme_class': 'SERPIN',
        'enzyme_class_group': 3,
        'pathway_category': 'Heme',
        'pathway_category_group': 4,
        'therapeutic_class': 'Anticoagulant',
        'therapeutic_class_group': 6,
        'phenotype_class': 'Heme',
        'phenotype_class_group': 0
    },
    'Ibuprofen': {
        'chemical_class': 'Aromatic',
        'chemical_class_group': 0,
        'target_class': 'Oxidoreductase',
        'target_class_group': 0,
        'enzyme_class': 'COX',
        'enzyme_class_group': 0,
        'pathway_category': 'Immune',
        'pathway_category_group': 0,
        'therapeutic_class': 'PDA closure',
        'therapeutic_class_group': 3,
        'phenotype_class': 'PDA closure',
        'phenotype_class_group': 3
    },
    'Iloprost': {
        'chemical_class': 'Aromatic',
        'chemical_class_group': 0,
        'target_class': 'GPCR',
        'target_class_group': 2,
        'enzyme_class': 'β-oxidation',
        'enzyme_class_group': 6,
        'pathway_category': 'Vasodilation',
        'pathway_category_group': 5,
        'therapeutic_class': 'Vasodilator',
        'therapeutic_class_group': 5,
        'phenotype_class': 'Vasodilator',
        'phenotype_class_group': 7
    },
    'Indomethacin': {
        'chemical_class': 'Aromatic',
        'chemical_class_group': 0,
        'target_class': 'Oxidoreductase',
        'target_class_group': 0,
        'enzyme_class': 'COX',
        'enzyme_class_group': 0,
        'pathway_category': 'Immune',
        'pathway_category_group': 0,
        'therapeutic_class': 'PDA closure',
        'therapeutic_class_group': 3,
        'phenotype_class': 'PDA closure',
        'phenotype_class_group': 3
    },
    'Prostaglandin E1': {
        'chemical_class': 'Oxygenated',
        'chemical_class_group': 5,
        'target_class': 'GPCR',
        'target_class_group': 2,
        'enzyme_class': 'β-oxidation',
        'enzyme_class_group': 6,
        'pathway_category': 'Vasodilation',
        'pathway_category_group': 5,
        'therapeutic_class': 'Vasodilator',
        'therapeutic_class_group': 5,
        'phenotype_class': 'Vasodilator',
        'phenotype_class_group': 7
    },
    'Sildenafil': {
        'chemical_class': 'Complex',
        'chemical_class_group': 4,
        'target_class': 'Hydrolase',
        'target_class_group': 6,
        'enzyme_class': 'PDE5',
        'enzyme_class_group': 4,
        'pathway_category': 'Vasodilation',
        'pathway_category_group': 5,
        'therapeutic_class': 'Vasodilator',
        'therapeutic_class_group': 5,
        'phenotype_class': 'Vasodilator',
        'phenotype_class_group': 7
    },
    'Sotalol': {
        'chemical_class': 'Heterocyclic',
        'chemical_class_group': 2,
        'target_class': 'Ion channel',
        'target_class_group': 3,
        'enzyme_class': 'Minimal hepatic metabolism',
        'enzyme_class_group': 5,
        'pathway_category': 'Cardio',
        'pathway_category_group': 1,
        'therapeutic_class': 'Antiarrhythmic',
        'therapeutic_class_group': 4,
        'phenotype_class': 'Cardio',
        'phenotype_class_group': 1
    },
    'Tadalafil': {
        'chemical_class': 'Heterocyclic',
        'chemical_class_group': 2,
        'target_class': 'Hydrolase',
        'target_class_group': 6,
        'enzyme_class': 'PDE5',
        'enzyme_class_group': 4,
        'pathway_category': 'Vasodilation',
        'pathway_category_group': 5,
        'therapeutic_class': 'Vasodilator',
        'therapeutic_class_group': 5,
        'phenotype_class': 'Vasodilator',
        'phenotype_class_group': 7
    }
}

# --- Drug-side effect mapping (from Table 1) ---
drug_side_effects = {
    'Amiodarone': ['Bradycardia', 'Hypotension', 'Hypothyroidism'],
    'Aspirin': ['Hematochezia'],
    'Atenolol': ['Palpitations', 'Asthma', 'Vertigo', 'Cold extremities'],
    'Captopril': ['Hypotension'],
    'Dexmedetomidine': ['Bradycardia'],
    'Sotalol': ['Bradycardia'],
    'Flecainide': ['Ventricular dysfunction'],
    'Furosemide': ['Hypokalemia', 'Hypovolemia', 'Bone fractures'],
    'Heparin': ['Thrombocytopenia', 'Postoperative bleeding'],
    'Indomethacin': ['Necrotizing enterocolitis', 'Gastrointestinal perforation', 'Oliguria',
                     'Anuria', 'Gastrointestinal hemorrhage', 'Intracerebral hemorrhage',
                     'Elevation of serum creatinine', 'Thrombocytopenia'],
    'Ibuprofen': ['Necrotizing enterocolitis', 'Tachypnoea', 'Retinopathy of prematurity',
                  'Intraventricular hemorrhage', 'Gastrointestinal hemorrhage'],
    'Iloprost': ['Facial flushing'],
    'Sildenafil': ['Facial flushing'],
    'Tadalafil': ['Headache'],
    'Prostaglandin E1': ['Apnea', 'Hypoventilation', 'Fever', 'Hyperthermia', 'Facial flushing']
}

# --- Multi-domain feature integration strategies (18 strategies as described) ---
feature_combinations = {
    'Clinical Only': ['clinical'],
    'Clinical+Chemical': ['clinical', 'chemical'],
    'Clinical+Biological': ['clinical', 'biological'],
    'Clinical+Phenotypic': ['clinical', 'phenotypic'],
    'Clinical+Chemical+Biological': ['clinical', 'chemical', 'biological'],
    'Clinical+Chemical+Phenotypic': ['clinical', 'chemical', 'phenotypic'],
    'Clinical+Biological+Phenotypic': ['clinical', 'biological', 'phenotypic'],
    'Clinical+Chemical+Biological+Phenotypic': ['clinical', 'chemical', 'biological', 'phenotypic'],
    'Clinical+Target': ['clinical', 'target'],
    'Clinical+Enzyme': ['clinical', 'enzyme'],
    'Clinical+Pathway': ['clinical', 'pathway'],
    'Clinical+Target+Enzyme': ['clinical', 'target', 'enzyme'],
    'Clinical+Target+Pathway': ['clinical', 'target', 'pathway'],
    'Clinical+Enzyme+Pathway': ['clinical', 'enzyme', 'pathway'],
    'Clinical+Therapeutic': ['clinical', 'therapeutic'],
    'Clinical+Phenotype_Class': ['clinical', 'phenotype_class'],
    'Clinical+Therapeutic+Phenotype_Class': ['clinical', 'therapeutic', 'phenotype_class'],
    'Clinical+Integrated_Cluster': ['clinical', 'integrated_cluster']
}

class MultiDomainDrugAnalyzer:
    def __init__(self):
        self.drug_descriptors = {}
        self.domain_clusters = {}
        self.integrated_clusters = {}
        
    def add_drug_classification_features(self, df):
        """Add Table 2 classification features to the dataframe"""
        for drug, classes in DRUG_CLASSIFICATION.items():
            mask = df['Drug name'] == drug
            for feature, value in classes.items():
                df.loc[mask, feature] = value
        return df
    
    def compute_chemical_fingerprints(self, smiles_dict):
        """Compute ECFP4 fingerprints for drugs"""
        fingerprints = {}
        for drug, smiles in smiles_dict.items():
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol:
                    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)
                    fingerprints[drug] = fp
                else:
                    print(f"Could not process SMILES for {drug}: {smiles}")
                    fingerprints[drug] = None
            except Exception as e:
                print(f"Error processing {drug}: {e}")
                fingerprints[drug] = None
        return fingerprints
    
    def compute_chemical_similarity(self, fp1, fp2):
        """Compute Tanimoto coefficient between two fingerprints"""
        if fp1 is None or fp2 is None:
            return 0.0
        return TanimotoSimilarity(fp1, fp2)
    
    def compute_jaccard_similarity(self, vec1, vec2):
        """Compute Jaccard similarity for binary vectors"""
        intersection = np.logical_and(vec1, vec2).sum()
        union = np.logical_or(vec1, vec2).sum()
        return intersection / union if union != 0 else 0.0
    
    def create_biological_vector(self, drug):
        """Create biological vector [target_class + enzyme_class + pathway_category]"""
        if drug not in DRUG_CLASSIFICATION:
            return np.zeros(20)  # 7 + 7 + 6 = 20 as per methodology
        
        classes = DRUG_CLASSIFICATION[drug]
        
        # Target classes (7 classes)
        target_classes = ['Ion channel', 'Oxidoreductase', 'GPCR', 'Peptidase', 
                         'Transporter', 'Protease Inhibitor', 'Hydrolase']
        target_vector = np.zeros(7)
        if classes['target_class'] in target_classes:
            idx = target_classes.index(classes['target_class'])
            target_vector[idx] = 1
        
        # Enzyme classes (7 classes)
        enzyme_classes = ['COX', 'ACE', 'Metabolized by CYP450', 'SERPIN', 
                         'PDE5', 'Minimal hepatic metabolism', 'β-oxidation']
        enzyme_vector = np.zeros(7)
        if classes['enzyme_class'] in enzyme_classes:
            idx = enzyme_classes.index(classes['enzyme_class'])
            enzyme_vector[idx] = 1
        
        # Pathway categories (6 classes)
        pathway_categories = ['Cardio', 'Immune', 'Neuro', 'Renal', 'Heme', 'Vasodilation']
        pathway_vector = np.zeros(6)
        if classes['pathway_category'] in pathway_categories:
            idx = pathway_categories.index(classes['pathway_category'])
            pathway_vector[idx] = 1
        
        # Concatenate biological vector
        biological_vector = np.concatenate([target_vector, enzyme_vector, pathway_vector])
        return biological_vector
    
    def create_phenotypic_vector(self, drug):
        """Create phenotypic vector [therapeutic_class + phenotype_class]"""
        if drug not in DRUG_CLASSIFICATION:
            return np.zeros(14)  # 8 + 6 = 14 as per methodology
        
        classes = DRUG_CLASSIFICATION[drug]
        
        # Therapeutic classes (8 classes)
        therapeutic_classes = ['Antiplatelet', 'Antihypertensive', 'Sedative', 'PDA closure',
                              'Antiarrhythmic', 'Diuretic', 'Anticoagulant', 'Vasodilator']
        therapeutic_vector = np.zeros(8)
        if classes['therapeutic_class'] in therapeutic_classes:
            idx = therapeutic_classes.index(classes['therapeutic_class'])
            therapeutic_vector[idx] = 1
        
        # Phenotype classes (6 classes)
        phenotype_classes = ['Cardio', 'Heme', 'Neuro', 'PDA closure', 'Renal', 'Vasodilator']
        phenotype_vector = np.zeros(6)
        if classes['phenotype_class'] in phenotype_classes:
            idx = phenotype_classes.index(classes['phenotype_class'])
            phenotype_vector[idx] = 1
        
        # Concatenate phenotypic vector
        phenotypic_vector = np.concatenate([therapeutic_vector, phenotype_vector])
        return phenotypic_vector
    
    def perform_domain_clustering(self, similarity_matrix, linkage_method='ward'):
        """Perform hierarchical clustering on domain similarity matrix"""
        dissimilarity = 1 - similarity_matrix
        linkage_matrix = sch.linkage(squareform(dissimilarity), method=linkage_method)
        return linkage_matrix

def load_and_preprocess_data():
    """Load and preprocess data according to methodology"""
    filepath = 'balanced_dataset2.xlsx'
    if not os.path.exists(filepath):
        # Create a sample dataset if file doesn't exist for testing
        print(f"Data file not found at: {filepath}. Creating sample data for testing.")
        return create_sample_dataset()
    
    df = pd.read_excel(filepath)
    df = df.dropna(subset=['Drug name'])
    
    # Initialize drug analyzer and add classification features
    analyzer = MultiDomainDrugAnalyzer()
    df = analyzer.add_drug_classification_features(df)
    
    # Data quality control - exclude records with >20% missing data
    missing_threshold = len(df.columns) * 0.2
    df = df.dropna(thresh=len(df.columns) - missing_threshold)
    
    # Handle missing values according to methodology
    for column in df.columns:
        if df[column].dtype in ['int64', 'float64']:
            # Continuous variables with <=10% missingness
            if df[column].isnull().mean() <= 0.1:
                df[column].fillna(df[column].median(), inplace=True)
        else:
            # Categorical variables - impute with mode
            if df[column].isnull().mean() <= 0.1:
                df[column].fillna(df[column].mode()[0] if not df[column].mode().empty else 'Unknown', inplace=True)
    
    # Create derived features
    if 'Age' in df.columns and 'Weight' in df.columns:
        df['Age_Weight_Ratio'] = df['Age'] / (df['Weight'].replace(0, 0.1))
    
    # Normalize continuous features using min-max scaling
    continuous_features = ['Age', 'Weight', 'Age_Weight_Ratio'] if 'Age_Weight_Ratio' in df.columns else ['Age', 'Weight']
    for feature in continuous_features:
        if feature in df.columns:
            scaler = MinMaxScaler()
            df[feature] = scaler.fit_transform(df[[feature]])
    
    return df

def create_sample_dataset():
    """Create a sample dataset for testing when main file is not available"""
    np.random.seed(42)
    n_samples = 1000
    
    drugs = list(DRUG_CLASSIFICATION.keys())
    data = []
    
    for _ in range(n_samples):
        drug = np.random.choice(drugs)
        side_effects = drug_side_effects.get(drug, [])
        
        record = {
            'Drug name': drug,
            'Age': np.random.uniform(1, 18),
            'Sex': np.random.choice(['Male', 'Female']),
            'Weight': np.random.uniform(10, 70),
            'Comorbidity': np.random.choice(['None', 'Mild', 'Moderate', 'Severe']),
            'Polypharmacy': np.random.randint(0, 10)
        }
        
        # Add side effect columns
        for se in ['Bradycardia', 'Hypotension', 'Hypothyroidism', 'Hematochezia', 
                   'Palpitations', 'Asthma', 'Vertigo', 'Cold extremities', 'Ventricular dysfunction',
                   'Hypokalemia', 'Hypovolemia', 'Bone fractures', 'Thrombocytopenia', 
                   'Postoperative bleeding', 'Necrotizing enterocolitis', 'Gastrointestinal perforation',
                   'Oliguria', 'Anuria', 'Gastrointestinal hemorrhage', 'Intracerebral hemorrhage',
                   'Elevation of serum creatinine', 'Tachypnoea', 'Retinopathy of prematurity',
                   'Intraventricular hemorrhage', 'Facial flushing', 'Headache', 'Apnea',
                   'Hypoventilation', 'Fever', 'Hyperthermia']:
            record[se] = 1 if se in side_effects and np.random.random() > 0.7 else 0
        
        data.append(record)
    
    df = pd.DataFrame(data)
    
    # Add classification features
    analyzer = MultiDomainDrugAnalyzer()
    df = analyzer.add_drug_classification_features(df)
    
    return df

def three_stage_feature_selection(X, y, n_features=20):
    """Three-stage feature selection process"""
    # Stage 1: Remove near-zero variance features (≤0.01)
    variance_selector = VarianceThreshold(threshold=0.01)
    X_variance = variance_selector.fit_transform(X)
    selected_features_variance = X.columns[variance_selector.get_support()]
    
    if len(selected_features_variance) == 0:
        return X.columns[:min(n_features, len(X.columns))], X.iloc[:, :min(n_features, len(X.columns))]
    
    # Stage 2: Mutual information - top 100 features
    if len(selected_features_variance) > 100:
        mi_scores = mutual_info_classif(X_variance, y, random_state=42)
        top_100_idx = np.argsort(mi_scores)[-100:]
        selected_features_mi = selected_features_variance[top_100_idx]
        X_mi = X_variance[:, top_100_idx]
    else:
        selected_features_mi = selected_features_variance
        X_mi = X_variance
    
    # Stage 3: RFECV with Random Forest
    rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
    rfecv = RFECV(estimator=rf, cv=StratifiedKFold(3), scoring='roc_auc', n_jobs=-1)
    
    try:
        rfecv.fit(X_mi, y)
        
        # Select final n_features
        if hasattr(rfecv, 'ranking_'):
            final_feature_idx = np.where(rfecv.ranking_ == 1)[0]
            if len(final_feature_idx) == 0:
                final_feature_idx = np.argsort(rfecv.ranking_)[:n_features]
            elif len(final_feature_idx) > n_features:
                final_feature_idx = final_feature_idx[:n_features]
        else:
            final_feature_idx = np.arange(min(n_features, X_mi.shape[1]))
        
        final_features = selected_features_mi[final_feature_idx]
        return final_features, X_mi[:, final_feature_idx] if hasattr(X_mi, 'iloc') else X_mi[:, final_feature_idx]
    
    except Exception as e:
        print(f"RFECV failed: {e}. Using top features by mutual information.")
        final_features = selected_features_mi[:min(n_features, len(selected_features_mi))]
        return final_features, X_mi[:, :min(n_features, X_mi.shape[1])]

def create_model_pipeline(model, numeric_features, categorical_features):
    """Create preprocessing pipeline with feature selection"""
    transformers = []
    
    if numeric_features:
        transformers.append(('num', StandardScaler(), numeric_features))
    if categorical_features:
        transformers.append(('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features))
    
    if transformers:
        preprocessor = ColumnTransformer(transformers)
    else:
        # If no features, use passthrough
        preprocessor = 'passthrough'
    
    return ImbPipeline([
        ('preprocessor', preprocessor),
        ('smote', SMOTE(random_state=42, k_neighbors=5)),
        ('classifier', model)
    ])

def evaluate_models_comprehensive(X, y, drug, side_effect, feature_name):
    """Comprehensive model evaluation with all performance metrics"""
    # Split data with stratification
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, stratify=y, random_state=42
        )
    except ValueError:
        # If stratification fails, use random split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
    
    # Feature selection on training data only
    try:
        selected_features, X_train_selected = three_stage_feature_selection(X_train, y_train)
        X_test_selected = X_test[selected_features]
    except Exception as e:
        print(f"Feature selection failed: {e}. Using all features.")
        selected_features = X_train.columns
        X_train_selected = X_train
        X_test_selected = X_test
    
    # Identify feature types
    numeric_features = X_train_selected.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_features = X_train_selected.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # Define models with comprehensive parameter grids
    models = {
        'Logistic Regression': {
            'model': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),
            'params': {
                'classifier__C': [0.1, 1, 10],
                'classifier__penalty': ['l2']
            }
        },
        'SVM': {
            'model': SVC(probability=True, random_state=42, class_weight='balanced'),
            'params': {
                'classifier__C': [0.1, 1, 10],
                'classifier__gamma': ['scale', 'auto']
            }
        },
        'Random Forest': {
            'model': RandomForestClassifier(random_state=42, class_weight='balanced'),
            'params': {
                'classifier__n_estimators': [100, 200],
                'classifier__max_depth': [10, 20, None]
            }
        },
        'KNN': {
            'model': KNeighborsClassifier(),
            'params': {
                'classifier__n_neighbors': [3, 5, 7],
                'classifier__weights': ['uniform', 'distance']
            }
        },
        'MLP': {
            'model': MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1, max_iter=200),
            'params': {
                'classifier__hidden_layer_sizes': [(128,), (128, 64), (128, 64, 32)],
                'classifier__alpha': [0.0001, 0.001]
            }
        }
    }
    
    fig = go.Figure()
    colors = px.colors.qualitative.Set1
    metrics_table = []
    best_models = {}
    
    for i, (name, model_config) in enumerate(models.items()):
        try:
            print(f"        Training {name}...")
            
            # Create pipeline
            pipeline = create_model_pipeline(model_config['model'], numeric_features, categorical_features)
            
            # Hyperparameter tuning with randomized search
            from sklearn.model_selection import RandomizedSearchCV
            random_search = RandomizedSearchCV(
                pipeline, model_config['params'], 
                n_iter=10, cv=3, scoring='roc_auc', 
                random_state=42, n_jobs=-1, error_score='raise'
            )
            
            random_search.fit(X_train_selected, y_train)
            best_pipeline = random_search.best_estimator_
            best_models[name] = best_pipeline
            
            # Predictions
            y_pred = best_pipeline.predict(X_test_selected)
            y_score = best_pipeline.predict_proba(X_test_selected)[:, 1]
            
            # Calculate metrics
            fpr, tpr, _ = roc_curve(y_test, y_score)
            roc_auc = auc(fpr, tpr)
            
            tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
            accuracy = (tp + tn) / (tp + tn + fp + fn)
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = sensitivity
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            metrics_table.append([
                name, sensitivity, specificity, accuracy, 
                precision, recall, f1, roc_auc
            ])
            
            # Add to ROC plot
            fig.add_trace(go.Scatter(
                x=fpr, y=tpr, mode='lines',
                name=f'{name} (AUC={roc_auc:.3f})',
                line=dict(color=colors[i % len(colors)], width=2)
            ))
            
            print(f"        {name}: AUC = {roc_auc:.3f}, F1 = {f1:.3f}")
            
        except Exception as e:
            print(f"        Error with {name}: {str(e)}")
            continue
    
    # Add random classifier line
    fig.add_trace(go.Scatter(
        x=[0, 1], y=[0, 1], mode='lines',
        name='Random (AUC=0.500)', line=dict(color='black', dash='dash')
    ))
    
    # Update plot layout
    fig.update_layout(
        title=f'{drug} - {side_effect} [{feature_name}]',
        xaxis_title='False Positive Rate',
        yaxis_title='True Positive Rate',
        legend=dict(orientation='h', y=-0.3),
        template='plotly_white',
        height=500,
        width=700
    )
    
    # Save plot
    out_name = f'AUROC_{drug}_{side_effect}_{feature_name}.html'.replace(" ", "_")
    fig.write_html(out_name)
    print(f"        Saved ROC plot to: {out_name}")
    
    # Create metrics table
    if metrics_table:
        metrics_df = pd.DataFrame(
            metrics_table, 
            columns=['Model', 'Sensitivity', 'Specificity', 'Accuracy', 
                    'Precision', 'Recall', 'F1 Score', 'AUROC']
        )
        
        print("\nPerformance Metrics:")
        print(metrics_df.round(3))
        
        # Create performance heatmap
        heatmap_data = metrics_df.set_index('Model')[['AUROC', 'F1 Score', 'Accuracy', 'Precision', 'Recall']]
        heatmap_fig = ff.create_annotated_heatmap(
            z=heatmap_data.values,
            x=heatmap_data.columns.tolist(),
            y=heatmap_data.index.tolist(),
            colorscale='Blues',
            showscale=True,
            annotation_text=np.round(heatmap_data.values, 3)
        )
        heatmap_fig.update_layout(
            title_text=f'Performance Heatmap: {drug} - {side_effect}',
            margin=dict(t=50, l=100)
        )
        heatmap_fig.write_html(f"Performance_Heatmap_{drug}_{side_effect}_{feature_name}.html".replace(" ", "_"))
    else:
        metrics_df = pd.DataFrame()
        print("No models were successfully trained.")
    
    return metrics_df, best_models

def main():
    """Main execution function"""
    print("🚀 Starting Multi-Domain Drug Side Effect Analysis...")
    
    # Load and preprocess data
    df = load_and_preprocess_data()
    print("✅ Data loaded and preprocessed. Shape:", df.shape)
    print("Available columns:", df.columns.tolist())
    
    # Perform analysis for each drug and side effect
    for drug, side_effects in drug_side_effects.items():
        print(f"\n🔬 Analyzing Drug: {drug}")
        
        for side_effect in side_effects:
            print(f"  ▶ Side Effect: {side_effect}")
            
            # Check if side effect exists in data
            if side_effect not in df.columns:
                print(f"    ⚠ Side effect '{side_effect}' not found in data. Skipping.")
                continue
            
            for feature_name, feature_groups in feature_combinations.items():
                print(f"    🔹 Feature Set: {feature_name}")
                
                try:
                    # Preprocess data for current drug and side effect
                    drug_data = df[df['Drug name'] == drug].copy()
                    
                    if drug_data.empty:
                        print(f"    ⚠ No data found for drug '{drug}'. Skipping.")
                        continue
                    
                    # Define available features based on methodology and Table 2
                    available_features = {
                        'clinical': ['Age', 'Sex', 'Weight', 'Comorbidity', 'Polypharmacy', 'Age_Weight_Ratio'],
                        'chemical': ['chemical_class', 'chemical_class_group'],
                        'biological': ['target_class', 'enzyme_class', 'pathway_category'],
                        'phenotypic': ['therapeutic_class', 'phenotype_class'],
                        'target': ['target_class', 'target_class_group'],
                        'enzyme': ['enzyme_class', 'enzyme_class_group'],
                        'pathway': ['pathway_category', 'pathway_category_group'],
                        'therapeutic': ['therapeutic_class', 'therapeutic_class_group'],
                        'phenotype_class': ['phenotype_class', 'phenotype_class_group'],
                        'integrated_cluster': ['chemical_class_group', 'target_class_group', 'enzyme_class_group', 
                                             'pathway_category_group', 'therapeutic_class_group', 'phenotype_class_group']
                    }
                    
                    # Select features based on current strategy
                    selected_features = []
                    for group in feature_groups:
                        if group in available_features:
                            # Only add features that exist in the dataframe
                            existing_features = [f for f in available_features[group] if f in drug_data.columns]
                            selected_features.extend(existing_features)
                    
                    # Remove duplicates and ensure we have features
                    selected_features = list(set(selected_features))
                    
                    if not selected_features:
                        print(f"    ⚠ No valid features found for strategy: {feature_name}")
                        continue
                    
                    X = drug_data[selected_features]
                    y = drug_data[side_effect].astype(int)
                    
                    # Check class balance
                    class_counts = y.value_counts()
                    if len(class_counts) < 2:
                        print(f"    ⚠ Insufficient class variety for '{side_effect}'. Class distribution: {class_counts.to_dict()}")
                        continue
                    
                    print(f"    📊 Class distribution: {class_counts.to_dict()}")
                    print(f"    🔧 Features used: {selected_features}")
                    
                    # Evaluate models
                    metrics_df, best_models = evaluate_models_comprehensive(
                        X, y, drug, side_effect, feature_name
                    )
                    
                    # Save results
                    if not metrics_df.empty:
                        results_file = f"Results_{drug}_{side_effect}_{feature_name}.csv".replace(" ", "_")
                        metrics_df.to_csv(results_file, index=False)
                        print(f"    💾 Results saved to: {results_file}")
                    
                except Exception as e:
                    print(f"    ❌ Error processing {drug}-{side_effect}-{feature_name}: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    continue
    
    print("\n🎯 Analysis completed!")

# --- Fix for Jupyter Notebook JSON issue ---
def fix_notebook_json_issue(notebook_path):
    """
    Fix for the 'Invalid Notebook - The Notebook Does Not Appear to Be Valid JSON' error
    """
    try:
        with open(notebook_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Try to parse as JSON
        notebook = json.loads(content)
        print(f"✅ Notebook {notebook_path} is valid JSON")
        return True
        
    except json.JSONDecodeError as e:
        print(f"❌ JSON Error in {notebook_path}: {e}")
        print("Attempting to fix the notebook...")
        
        # Common fixes for notebook issues
        try:
            # Remove any trailing commas
            content = content.replace(',\n}', '\n}').replace(',\n]', '\n]')
            
            # Fix common encoding issues
            content = content.encode('utf-8').decode('utf-8')
            
            # Write back the fixed content
            with open(notebook_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"✅ Fixed notebook: {notebook_path}")
            return True
            
        except Exception as fix_error:
            print(f"❌ Could not fix notebook: {fix_error}")
            return False

if __name__ == '__main__':
    # If you need to fix notebook JSON issues, uncomment the line below
    # fix_notebook_json_issue('your_notebook.ipynb')
    
    main()
