{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d68e68-4e08-4bad-a055-91ca46ce120b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded. Shape: (3592, 45)\n",
      "\n",
      "ðŸ”¬ Drug: Amiodarone\n",
      "  â–¶ Side effect: Bradycardia\n",
      "    ðŸ”¹ Feature Set: Clinical Only\n",
      "        SVM: AUC = 0.844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 238\u001b[0m\n\u001b[0;32m    235\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    âš  Skipping: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 238\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[7], line 233\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m preprocess_data(df, drug, side_effect, feature_groups)\n\u001b[1;32m--> 233\u001b[0m     evaluate_models_and_plot(X, y, drug, side_effect, feature_name)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    âš  Skipping: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 155\u001b[0m, in \u001b[0;36mevaluate_models_and_plot\u001b[1;34m(X, y, drug, side_effect, feature_name)\u001b[0m\n\u001b[0;32m    153\u001b[0m base_pipeline \u001b[38;5;241m=\u001b[39m create_model_pipeline(model, numeric_features, categorical_features)\n\u001b[0;32m    154\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(base_pipeline, param_grid[name], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 155\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m    156\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    157\u001b[0m best_model \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "\n",
    "# --- Suppress Warnings ---\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# --- Drug-side effect mapping ---\n",
    "drug_side_effects = {\n",
    "    'Amiodarone': ['Bradycardia', 'Hypotension', 'Hypothyroidism'],\n",
    "    'Aspirin': ['Hematochezia'],\n",
    "    'Atenolol': ['Palpitations', 'Asthma', 'Vertigo', 'Cold extremities'],\n",
    "    'Captopril': ['Hypotension'],\n",
    "    'Dexmedetomidine': ['Bradycardia'],\n",
    "    'Sotalol': ['Bradycardia'],\n",
    "    'Flecainide': ['Ventricular dysfunction'],\n",
    "    'Furosemide': ['Hypokalemia', 'Hypovolemia', 'Bone fractures'],\n",
    "    'Heparin': ['Thrombocytopenia', 'Postoperative bleeding'],\n",
    "    'Indomethacin': ['Necrotizing enterocolitis', 'Gastrointestinal perforation', 'Oliguria',\n",
    "                     'Anuria', 'Gastrointestinal hemorrhage', 'Intracerebral hemorrhage',\n",
    "                     'Elevation of serum creatinine', 'Thrombocytopenia'],\n",
    "    'Ibuprofen': ['Necrotizing enterocolitis', 'Tachypnoea', 'Retinopathy of prematurity',\n",
    "                  'Intraventricular hemorrhage', 'Gastrointestinal hemorrhage'],\n",
    "    'Iloprost': ['Facial flushing'],\n",
    "    'Sildenafil': ['Facial flushing'],\n",
    "    'Tadalafil': ['Headache'],\n",
    "    'Prostaglandin E1': ['Apnea', 'Hypoventilation', 'Fever', 'Hyperthermia', 'Facial flushing']\n",
    "}\n",
    "\n",
    "# --- Feature combinations ---\n",
    "feature_combinations = {\n",
    "    'Clinical Only': ['clinical'],\n",
    "    'Clinical+Chemical': ['clinical', 'chemical'],\n",
    "    'Clinical+Target': ['clinical', 'target'],\n",
    "    'Clinical+Enzyme': ['clinical', 'enzyme'],\n",
    "    'Clinical+Pathway': ['clinical', 'pathway'],\n",
    "    'Clinical+Target+Enzyme': ['clinical', 'target', 'enzyme'],\n",
    "    'Clinical+Target+Pathway': ['clinical', 'target', 'pathway'],\n",
    "    'Clinical+Enzyme+Pathway': ['clinical', 'enzyme', 'pathway'],\n",
    "    'Clinical+Therapeutic': ['clinical', 'therapeutic'],\n",
    "    'Clinical+Phenotype': ['clinical', 'phenotype'],\n",
    "    'Clinical+Therapeutic+Phenotype': ['clinical', 'therapeutic', 'phenotype']\n",
    "}\n",
    "\n",
    "def load_data():\n",
    "    filepath =  'balanced_dataset2.xlsx'\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Data file not found at: {filepath}\")\n",
    "    \n",
    "    df = pd.read_excel(filepath)\n",
    "    df = df.dropna(subset=['Drug name'])\n",
    "\n",
    "    if 'Age' in df.columns and 'Weight' in df.columns:\n",
    "        df['Age_Weight_Ratio'] = df['Age'] / (df['Weight'].replace(0, 0.1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, drug_name, target_col, feature_groups):\n",
    "    drug_data = df[df['Drug name'] == drug_name].copy()\n",
    "    available_features = {\n",
    "        'clinical': ['Age', 'Sex', 'Weight', 'Comorbidity', 'Polypharmacy', 'Age_Weight_Ratio'],\n",
    "        'chemical': ['Chemical Class'],\n",
    "        'target': ['Target Protein'],\n",
    "        'enzyme': ['Enzyme'],\n",
    "        'pathway': ['Pathway Category'],\n",
    "        'therapeutic': ['Therapeutic Class'],\n",
    "        'phenotype': ['Phenotype']\n",
    "    }\n",
    "\n",
    "    selected_features = []\n",
    "    for group in feature_groups:\n",
    "        if group in available_features:\n",
    "            selected_features.extend([f for f in available_features[group] if f in drug_data.columns])\n",
    "    \n",
    "    if not selected_features:\n",
    "        raise ValueError(f\"No valid features found for groups: {feature_groups}\")\n",
    "    \n",
    "    X = drug_data[selected_features]\n",
    "    y = drug_data[target_col].astype(int)\n",
    "    \n",
    "    if len(y.unique()) < 2:\n",
    "        raise ValueError(f\"Insufficient classes in target '{target_col}' for drug '{drug_name}'\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_model_pipeline(model, numeric_features, categorical_features):\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "    return ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "def evaluate_models_and_plot(X, y, drug, side_effect, feature_name):\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "     \n",
    "    models = {\n",
    "        'SVM': SVC(probability=True, random_state=42),\n",
    "        'MLP': MLPClassifier(random_state=42),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Logistic': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    }\n",
    "\n",
    "    fig = go.Figure()\n",
    "    colors = px.colors.qualitative.Set1\n",
    "    aucs = []\n",
    "    metrics_table = []\n",
    "\n",
    "    for i, (name, model) in enumerate(models.items()):\n",
    "        try:\n",
    "            param_grid = {\n",
    "                'SVM': {'classifier__C': [0.1, 1, 10], 'classifier__gamma': ['scale', 'auto']},\n",
    "                'MLP': {'classifier__hidden_layer_sizes': [(150,), (100,)], 'classifier__alpha': [0.0001, 0.001]},\n",
    "                'KNN': {'classifier__n_neighbors': [3, 5, 7]},\n",
    "                'Logistic': {'classifier__C': [0.1, 1, 10]},\n",
    "                'Random Forest': {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]},\n",
    "            }\n",
    "       \n",
    "            base_pipeline = create_model_pipeline(model, numeric_features, categorical_features)\n",
    "            search = GridSearchCV(base_pipeline, param_grid[name], cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "            search.fit(X, y)\n",
    "            pipeline = search.best_estimator_\n",
    "            best_model = pipeline.named_steps['classifier']\n",
    "\n",
    "            y_score = pipeline.predict_proba(X)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y, y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "\n",
    "            y_pred = pipeline.predict(X)\n",
    "            tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "            sensitivity = tp / (tp + fn)\n",
    "            specificity = tn / (tn + fp)\n",
    "            accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            metrics_table.append([name, sensitivity, specificity, accuracy, recall, f1, roc_auc])\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=fpr, y=tpr, mode='lines',\n",
    "                name=f'{name} (AUC={roc_auc:.2f})',\n",
    "                line=dict(color=colors[i % len(colors)], width=2)\n",
    "            ))\n",
    "            print(f\"        {name}: AUC = {roc_auc:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"        Error with {name}: {str(e)}\")\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0, 1], y=[0, 1], mode='lines',\n",
    "        name='Random (AUC=0.50)', line=dict(color='black', dash='dash')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f'{drug} - {side_effect} [{feature_name}]',\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis_title='True Positive Rate',\n",
    "        legend=dict(orientation='h', y=-0.2),\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    out_name = f'AUROC_{drug}_{side_effect}_{feature_name}.html'.replace(\" \", \"_\")\n",
    "    fig.write_html(out_name)\n",
    "    print(f\"        Saved plot to: {out_name}\")\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_table, columns=['Model', 'Sensitivity', 'Specificity', 'Accuracy', 'Recall', 'F1 Score', 'AUROC'])\n",
    "    print(\"\\nMetrics Table:\")\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Heatmap of AUCs\n",
    "    heatmap_df = pd.DataFrame([aucs], columns=models.keys(), index=[side_effect])\n",
    "    heatmap_fig = ff.create_annotated_heatmap(\n",
    "        z=heatmap_df.values.tolist(),\n",
    "        x=heatmap_df.columns.tolist(),\n",
    "        y=heatmap_df.index.tolist(),\n",
    "        colorscale='Blues',\n",
    "        showscale=True\n",
    "    )\n",
    "    heatmap_fig.update_layout(\n",
    "        title_text=f'AUC Heatmap: {drug} - {side_effect}',\n",
    "        margin=dict(t=50, l=100)\n",
    "    )\n",
    "    heatmap_fig.write_html(f\"Heatmap_{drug}_{side_effect}_{feature_name}.html\".replace(\" \", \"_\"))\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def main():\n",
    "    df = load_data()\n",
    "    print(\"âœ… Data loaded. Shape:\", df.shape)\n",
    "\n",
    "    for drug, side_effects in drug_side_effects.items():\n",
    "        print(f\"\\nðŸ”¬ Drug: {drug}\")\n",
    "        for side_effect in side_effects:\n",
    "            print(f\"  â–¶ Side effect: {side_effect}\")\n",
    "            for feature_name, feature_groups in feature_combinations.items():\n",
    "                print(f\"    ðŸ”¹ Feature Set: {feature_name}\")\n",
    "                try:\n",
    "                    X, y = preprocess_data(df, drug, side_effect, feature_groups)\n",
    "                    evaluate_models_and_plot(X, y, drug, side_effect, feature_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"    âš  Skipping: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1701832-1445-49d4-aaf9-adff8b94110a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
